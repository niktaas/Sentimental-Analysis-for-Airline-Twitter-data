{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_data = pd.read_csv('airline-train.csv')\n",
    "test_data = pd.read_csv('airline-test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess\n",
    "\n",
    "#import re\n",
    "import nltk\n",
    "#from nltk import stopwords\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "#from string import punctuation \n",
    "\n",
    "\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from string import punctuation \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "class PreProcessTweets:\n",
    "    def __init__(self):\n",
    "        self._stopwords = set(stopwords.words('english') + list(punctuation) + ['AT_USER','URL'])\n",
    "        \n",
    "    def processTweets(self, list_of_tweets):\n",
    "        processedTweets=[]\n",
    "        text_of_tweet = list_of_tweets[\"text\"]\n",
    "\n",
    "                \n",
    "        for tweet in text_of_tweet:\n",
    "            processedTweets.append(( self._processTweet(tweet) ))\n",
    "        return processedTweets\n",
    "    \n",
    "    def _processTweet(self, tweet):\n",
    "        ps = PorterStemmer()\n",
    "        tweet = tweet.lower() # convert text to lower-case\n",
    "        tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))', 'URL', tweet) # remove URLs\n",
    "        tweet = re.sub('@[^\\s]+', 'AT_USER', tweet) # remove usernames\n",
    "        tweet = re.sub(r'#([^\\s]+)', r'\\1', tweet) # remove the # in #hashtag\n",
    "        tweet = word_tokenize(tweet) # remove repeated characters (helloooooooo into hello)\n",
    "        return [ps.stem(word) for word in tweet if word not in self._stopwords and len(ps.stem(word))>=3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetProcessor = PreProcessTweets()\n",
    "preprocessed_train_data = tweetProcessor.processTweets(train_data)\n",
    "preprocessed_test_data = tweetProcessor.processTweets(test_data)\n",
    "\n",
    "train_data[\"text\"] = preprocessed_train_data\n",
    "test_data[\"text\"] = preprocessed_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>_golden</th>\n",
       "      <th>_unit_state</th>\n",
       "      <th>_trusted_judgments</th>\n",
       "      <th>_last_judgment_at</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment:confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason:confidence</th>\n",
       "      <th>...</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11429</td>\n",
       "      <td>681462729</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 3:07</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CaraModisett</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[also, appreci, hashtag, lucycat]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/18/15 10:55</td>\n",
       "      <td>5.681220e+17</td>\n",
       "      <td>Memphis, Tennessee</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9717</td>\n",
       "      <td>681461003</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 3:20</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>0.3464</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LarrySandeen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[discov, bill, 300, reschedul, flight, cost, s...</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>2/22/15 19:24</td>\n",
       "      <td>5.696990e+17</td>\n",
       "      <td>Southeastern Pennsylvania USA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10153</td>\n",
       "      <td>681461443</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 6:20</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>burseka</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[guy, suck]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/22/15 7:28</td>\n",
       "      <td>5.695190e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>975</td>\n",
       "      <td>681449647</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 2:14</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>artistanxiety</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[right, angri]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/23/15 14:09</td>\n",
       "      <td>5.699820e+17</td>\n",
       "      <td>Punk is the preacher.</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1511</td>\n",
       "      <td>681450373</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 6:57</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>0.6848</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>axelrodaj</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[sure, peopl, row, paid, premium, seat, n't, u...</td>\n",
       "      <td>[33.94077727, -118.39921036]</td>\n",
       "      <td>2/22/15 18:50</td>\n",
       "      <td>5.696910e+17</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   _unit_id  _golden _unit_state  _trusted_judgments  \\\n",
       "0       11429  681462729    False   finalized                   3   \n",
       "1        9717  681461003    False   finalized                   3   \n",
       "2       10153  681461443    False   finalized                   3   \n",
       "3         975  681449647    False   finalized                   3   \n",
       "4        1511  681450373    False   finalized                   3   \n",
       "\n",
       "  _last_judgment_at airline_sentiment  airline_sentiment:confidence  \\\n",
       "0      2/25/15 3:07          positive                           1.0   \n",
       "1      2/25/15 3:20          negative                           1.0   \n",
       "2      2/25/15 6:20          negative                           1.0   \n",
       "3      2/25/15 2:14          negative                           1.0   \n",
       "4      2/25/15 6:57          negative                           1.0   \n",
       "\n",
       "  negativereason  negativereason:confidence  ... airline_sentiment_gold  \\\n",
       "0            NaN                        NaN  ...                    NaN   \n",
       "1     Can't Tell                     0.3464  ...                    NaN   \n",
       "2     Can't Tell                     1.0000  ...                    NaN   \n",
       "3     Can't Tell                     1.0000  ...                    NaN   \n",
       "4     Can't Tell                     0.6848  ...                    NaN   \n",
       "\n",
       "            name negativereason_gold retweet_count  \\\n",
       "0   CaraModisett                 NaN             0   \n",
       "1   LarrySandeen                 NaN             0   \n",
       "2        burseka                 NaN             0   \n",
       "3  artistanxiety                 NaN             0   \n",
       "4      axelrodaj                 NaN             0   \n",
       "\n",
       "                                                text  \\\n",
       "0                  [also, appreci, hashtag, lucycat]   \n",
       "1  [discov, bill, 300, reschedul, flight, cost, s...   \n",
       "2                                        [guy, suck]   \n",
       "3                                     [right, angri]   \n",
       "4  [sure, peopl, row, paid, premium, seat, n't, u...   \n",
       "\n",
       "                    tweet_coord  tweet_created      tweet_id  \\\n",
       "0                           NaN  2/18/15 10:55  5.681220e+17   \n",
       "1                    [0.0, 0.0]  2/22/15 19:24  5.696990e+17   \n",
       "2                           NaN   2/22/15 7:28  5.695190e+17   \n",
       "3                           NaN  2/23/15 14:09  5.699820e+17   \n",
       "4  [33.94077727, -118.39921036]  2/22/15 18:50  5.696910e+17   \n",
       "\n",
       "                  tweet_location               user_timezone  \n",
       "0             Memphis, Tennessee  Central Time (US & Canada)  \n",
       "1  Southeastern Pennsylvania USA                         NaN  \n",
       "2                            NaN                         NaN  \n",
       "3          Punk is the preacher.                     Arizona  \n",
       "4                  San Francisco  Pacific Time (US & Canada)  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection with chi 2\n",
    "#unique words of all tweets\n",
    "import sklearn\n",
    "\n",
    "unique_words = []\n",
    "\n",
    "for i in range (0,len(train_data)):\n",
    "    for word in train_data[\"text\"][i] :\n",
    "        if word not in unique_words:\n",
    "            unique_words.append(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['also',\n",
       " 'appreci',\n",
       " 'hashtag',\n",
       " 'lucycat',\n",
       " 'discov',\n",
       " 'bill',\n",
       " '300',\n",
       " 'reschedul',\n",
       " 'flight',\n",
       " 'cost',\n",
       " 'second',\n",
       " 'day',\n",
       " 'lost',\n",
       " 'work',\n",
       " 'guy',\n",
       " 'suck',\n",
       " 'right',\n",
       " 'angri',\n",
       " 'sure',\n",
       " 'peopl',\n",
       " 'row',\n",
       " 'paid',\n",
       " 'premium',\n",
       " 'seat',\n",
       " \"n't\",\n",
       " 'use',\n",
       " 'overhead',\n",
       " 'space',\n",
       " '...',\n",
       " 'cancel',\n",
       " 'there\\x89ûª',\n",
       " 'way',\n",
       " 'rebook',\n",
       " 'websit',\n",
       " 'app',\n",
       " 'wait',\n",
       " 'minut',\n",
       " 'hold',\n",
       " 'fail',\n",
       " 'need',\n",
       " 'help',\n",
       " 'miss',\n",
       " 'bag',\n",
       " 'say',\n",
       " 'deliv',\n",
       " 'local',\n",
       " 'number',\n",
       " 'open',\n",
       " 'ask',\n",
       " 'main',\n",
       " 'cust',\n",
       " 'servic',\n",
       " 'got',\n",
       " 'hung',\n",
       " 'start',\n",
       " 'daili',\n",
       " 'b777-200er',\n",
       " 'newark',\n",
       " 'frankfurt',\n",
       " 'replac',\n",
       " 'b767-400er',\n",
       " '2jul',\n",
       " 'avgeek',\n",
       " 'think',\n",
       " 'problem',\n",
       " 'saturday',\n",
       " 'due',\n",
       " 'expect',\n",
       " 'snow',\n",
       " 'anyon',\n",
       " 'ua1740',\n",
       " 'inbound',\n",
       " 'dep',\n",
       " 'time',\n",
       " 'get',\n",
       " 'closer',\n",
       " 'push',\n",
       " 'back',\n",
       " 'min',\n",
       " \"'ve\",\n",
       " 'thank',\n",
       " 'respons',\n",
       " 'hour',\n",
       " 'realli',\n",
       " 'frustrat',\n",
       " 'seem',\n",
       " 'like',\n",
       " 'one',\n",
       " 'jetblu',\n",
       " 'concern',\n",
       " 'hope',\n",
       " 'destin',\n",
       " 'guarante',\n",
       " \"'ll\",\n",
       " 'see',\n",
       " 'tomorrow',\n",
       " 'morn',\n",
       " 'fight',\n",
       " 'look',\n",
       " 'fix',\n",
       " 'arriv',\n",
       " 'schedul',\n",
       " 'outbound',\n",
       " 'departur',\n",
       " 'still',\n",
       " '\\x89ûïat_us',\n",
       " 'pleas',\n",
       " 'reach',\n",
       " 'crewmemb',\n",
       " 'assist',\n",
       " 'apolog',\n",
       " 'long',\n",
       " 'wait.\\x89û\\x9d',\n",
       " 'gener',\n",
       " 'would',\n",
       " 'made',\n",
       " 'alreadi',\n",
       " 'book',\n",
       " 'anoth',\n",
       " 'origin',\n",
       " 'reserv',\n",
       " 'ua1673',\n",
       " 'suppos',\n",
       " 'depart',\n",
       " '9:08',\n",
       " 'terribl',\n",
       " 'travel',\n",
       " 'experi',\n",
       " '8000',\n",
       " 'mile',\n",
       " 'roundtrip',\n",
       " 'two',\n",
       " 'flightlat',\n",
       " 'short',\n",
       " 'hop',\n",
       " 'land',\n",
       " 'earli',\n",
       " 'snowfal',\n",
       " 'robert',\n",
       " 'amp',\n",
       " 's=1',\n",
       " 'best',\n",
       " 'first',\n",
       " 'class',\n",
       " 'ever',\n",
       " 'gotten',\n",
       " 'denver',\n",
       " 'lax',\n",
       " 'wonder',\n",
       " 'channel',\n",
       " 'year',\n",
       " 'luckili',\n",
       " 'disappoint',\n",
       " 'lack',\n",
       " 'commun',\n",
       " 'joke',\n",
       " 'compani',\n",
       " 'today',\n",
       " 'remind',\n",
       " 'never',\n",
       " 'tri',\n",
       " 'dpdfpp',\n",
       " 're-book',\n",
       " 'american',\n",
       " 'unit',\n",
       " 'said',\n",
       " 'transfer',\n",
       " 'fact',\n",
       " 'even',\n",
       " 'flightl',\n",
       " 'email',\n",
       " 'sever',\n",
       " 'times.hand',\n",
       " 'wrote',\n",
       " 'letter',\n",
       " 'went',\n",
       " 'airport',\n",
       " 'called.pleas',\n",
       " 'know',\n",
       " 'keep',\n",
       " 'money',\n",
       " 'regard',\n",
       " 'updat',\n",
       " 'releas',\n",
       " 'septemb',\n",
       " 'found',\n",
       " 'fli',\n",
       " 'direct',\n",
       " 'lbb',\n",
       " 'excit',\n",
       " 'tripofalifetim',\n",
       " 'employe',\n",
       " 'logan',\n",
       " 'told',\n",
       " 'final',\n",
       " 'meet',\n",
       " 'daughter',\n",
       " 'solo',\n",
       " 'rude',\n",
       " 'rep',\n",
       " 'bring',\n",
       " 'guitar',\n",
       " 'carri',\n",
       " 'happen',\n",
       " 'take',\n",
       " 'issu',\n",
       " 'want',\n",
       " 'pay',\n",
       " 'inaccess',\n",
       " 'new',\n",
       " 'wors',\n",
       " 'americanairlin',\n",
       " 'nocustomerservic',\n",
       " 'fill',\n",
       " 'form',\n",
       " 'sent',\n",
       " 'address',\n",
       " 'flt',\n",
       " '1202',\n",
       " 'delay',\n",
       " 'let',\n",
       " 'plane',\n",
       " 'toilet',\n",
       " 'done',\n",
       " 'goe',\n",
       " 'famili',\n",
       " 'vacay',\n",
       " 'playa',\n",
       " 'del',\n",
       " 'carmen',\n",
       " 'mexico',\n",
       " 'neveragain',\n",
       " 'umm',\n",
       " 'defin',\n",
       " \"'extra\",\n",
       " 'utah',\n",
       " 'good',\n",
       " 'much',\n",
       " 'sound',\n",
       " 'thin',\n",
       " 'devic',\n",
       " 'person',\n",
       " 'loyalti',\n",
       " 'team',\n",
       " 'basic',\n",
       " 'flip',\n",
       " 'via',\n",
       " 'phone',\n",
       " 'mayb',\n",
       " 'googl',\n",
       " '^lol',\n",
       " 'biggest',\n",
       " 'longer',\n",
       " 'abl',\n",
       " 'check',\n",
       " 'onlin',\n",
       " 'could',\n",
       " 'give',\n",
       " 'free',\n",
       " 'life',\n",
       " 'choos',\n",
       " 'purchas',\n",
       " 'ticket',\n",
       " 'competitor',\n",
       " 'leav',\n",
       " 'soon',\n",
       " 'realiz',\n",
       " 'figur',\n",
       " 'steal',\n",
       " 'secur',\n",
       " 'camera',\n",
       " 'anyth',\n",
       " '894',\n",
       " 'offic',\n",
       " 'wow',\n",
       " 'unreal',\n",
       " 'staff',\n",
       " 'board',\n",
       " 'announc',\n",
       " 'airway',\n",
       " 'site',\n",
       " 'link',\n",
       " 'last',\n",
       " 'night',\n",
       " 'though',\n",
       " 'checkin',\n",
       " '2:00',\n",
       " 'tmrw',\n",
       " 'cancun',\n",
       " 'undefin',\n",
       " 'error',\n",
       " '800',\n",
       " 'working.famili',\n",
       " 'cgroup',\n",
       " 'point',\n",
       " 'shop',\n",
       " 'post',\n",
       " 'account',\n",
       " 'earn',\n",
       " 'nightmar',\n",
       " 'yesterday',\n",
       " 'zero',\n",
       " 'tweet',\n",
       " 'well',\n",
       " 'total',\n",
       " 'kick',\n",
       " 'million',\n",
       " 'pound',\n",
       " 'ass',\n",
       " 'bar',\n",
       " 'none',\n",
       " 'airlin',\n",
       " 'industri',\n",
       " 'opinion',\n",
       " 'test',\n",
       " 'patienc',\n",
       " 'shall',\n",
       " 'gate',\n",
       " 'find',\n",
       " 'agent',\n",
       " '130am',\n",
       " 'mia-ewr',\n",
       " '384',\n",
       " '_ù÷ã_ù÷ã_ù÷ã',\n",
       " 'excel',\n",
       " 'crew',\n",
       " 'ewr-iad',\n",
       " '3589',\n",
       " '_ù÷á_ù÷á_ù÷á',\n",
       " 'load',\n",
       " 'door',\n",
       " 'freez',\n",
       " 'past',\n",
       " 'dal',\n",
       " 'sleet',\n",
       " 'sun',\n",
       " 'eve-did',\n",
       " 'list',\n",
       " 'citi',\n",
       " 'dca',\n",
       " '8:10',\n",
       " 'attend',\n",
       " 'typic',\n",
       " 'compens',\n",
       " 'might',\n",
       " 'unaccept',\n",
       " 'hah',\n",
       " 'happi',\n",
       " 'screw',\n",
       " 'carrier',\n",
       " 'hahahah',\n",
       " 'pathet',\n",
       " 'sato',\n",
       " 'upset',\n",
       " 'call',\n",
       " 'appropri',\n",
       " 'review',\n",
       " 'nada',\n",
       " 'avail',\n",
       " 'next',\n",
       " 'full',\n",
       " 'refund',\n",
       " 'contact',\n",
       " 'offer',\n",
       " '1000',\n",
       " 'certif',\n",
       " 'unitedairlin',\n",
       " 'custom',\n",
       " 'fll',\n",
       " 'bwi',\n",
       " 'pit',\n",
       " 'terrible.no',\n",
       " 'are.hi',\n",
       " 'job',\n",
       " 'cloth',\n",
       " 'gear',\n",
       " '8:30',\n",
       " 'cater',\n",
       " 'strike',\n",
       " 'jfk',\n",
       " 'chging',\n",
       " 'isit',\n",
       " 'possibl',\n",
       " 'fare',\n",
       " 'differ',\n",
       " 'dollar',\n",
       " 'bought',\n",
       " 'complet',\n",
       " 'redempt',\n",
       " 'yet',\n",
       " 'high',\n",
       " 'everyth',\n",
       " 'far',\n",
       " 'anchorag',\n",
       " 'fairbank',\n",
       " 'misread',\n",
       " 'end',\n",
       " 'date',\n",
       " '2014',\n",
       " '2015.',\n",
       " 'clarifi',\n",
       " 'car',\n",
       " 'reimburs',\n",
       " 'pair',\n",
       " 'shoe',\n",
       " 'necess',\n",
       " 'child',\n",
       " 'sick',\n",
       " 'toyingwithouremot',\n",
       " 'care',\n",
       " '1891.',\n",
       " 'caus',\n",
       " 'failur',\n",
       " 'dont',\n",
       " 'mean',\n",
       " 'isnt',\n",
       " 'first-time-flying-w-a-16mo',\n",
       " 'old',\n",
       " 'likelihood',\n",
       " 'addtl',\n",
       " '2nt',\n",
       " 'tell',\n",
       " 'sydney',\n",
       " 'australia',\n",
       " 'pref',\n",
       " 'asia',\n",
       " 'pac',\n",
       " 'voucher',\n",
       " 'redeem',\n",
       " 'robot',\n",
       " 'answer',\n",
       " 'noth',\n",
       " 'given',\n",
       " 'circumst',\n",
       " 'feel',\n",
       " 'must',\n",
       " 'someth',\n",
       " 'spoke',\n",
       " 'suggest',\n",
       " 'voic',\n",
       " 'moment',\n",
       " 'ago',\n",
       " 'yeah',\n",
       " 'incident',\n",
       " 'spend',\n",
       " 'trip',\n",
       " 'wast',\n",
       " 'comedian',\n",
       " 'promis',\n",
       " 'make',\n",
       " 'fun',\n",
       " 'stage',\n",
       " 'tonight',\n",
       " 'stuff',\n",
       " 'legal',\n",
       " 'blind',\n",
       " 'mess',\n",
       " 'sleep',\n",
       " 'stay',\n",
       " 'cherri',\n",
       " 'top-flight',\n",
       " '880',\n",
       " 'runway',\n",
       " 'half',\n",
       " 'luggag',\n",
       " 'respond',\n",
       " 'promptli',\n",
       " 'forward',\n",
       " '240',\n",
       " 'drive',\n",
       " 'file',\n",
       " 'claim',\n",
       " 'shiz',\n",
       " 'barrier',\n",
       " 'unbeliev',\n",
       " 'hire',\n",
       " 'pilot',\n",
       " 'ruin',\n",
       " 'allow',\n",
       " 'buddi',\n",
       " 'turn',\n",
       " '30.',\n",
       " 'unitedsucksdick',\n",
       " 'may',\n",
       " 'hawaii',\n",
       " 'sanfrancisco',\n",
       " 'biztravel',\n",
       " 'poor',\n",
       " 'gestur',\n",
       " 'goodwil',\n",
       " 'top',\n",
       " 'statu',\n",
       " 'flyer',\n",
       " 'aa91',\n",
       " 'lhr-ord',\n",
       " '2/16',\n",
       " 'babi',\n",
       " 'hannah',\n",
       " 'save',\n",
       " 'surgeri',\n",
       " 'requires.sh',\n",
       " 'help.pl',\n",
       " 'donate/rt',\n",
       " 'sit',\n",
       " 'hanger',\n",
       " 'numer',\n",
       " 'mechan',\n",
       " 'actual',\n",
       " 'mainten',\n",
       " 'cool',\n",
       " 'home',\n",
       " 'hous',\n",
       " '-30',\n",
       " 'wind',\n",
       " 'chill',\n",
       " 'jet',\n",
       " 'lol',\n",
       " 'love',\n",
       " 'brother',\n",
       " 'hot',\n",
       " 'weather',\n",
       " 'great',\n",
       " 'nightlif',\n",
       " '2-3',\n",
       " 'pain',\n",
       " 'chang',\n",
       " 'cut',\n",
       " 'alway',\n",
       " 'vacat',\n",
       " 'heard',\n",
       " 'your',\n",
       " 'plan',\n",
       " 'compart',\n",
       " 'effici',\n",
       " 'consult',\n",
       " 'manag',\n",
       " 'phx',\n",
       " 'baggag',\n",
       " 'mani',\n",
       " 'kiosk',\n",
       " '100',\n",
       " 'ppl',\n",
       " 'faster',\n",
       " 'columbia',\n",
       " 'clt',\n",
       " 'ua2066',\n",
       " 'cnx',\n",
       " 'pax',\n",
       " 'frm',\n",
       " 'ua6194',\n",
       " 'runner',\n",
       " 'fam',\n",
       " 'miscnx',\n",
       " 'twitter',\n",
       " 'watch',\n",
       " 'messag',\n",
       " 'okay',\n",
       " 'week',\n",
       " 'repli',\n",
       " 'chicago-lax-phx',\n",
       " 'spot',\n",
       " 'chicago',\n",
       " 'lekvhg',\n",
       " '430',\n",
       " '.at_us',\n",
       " 'wish',\n",
       " 'austin',\n",
       " 'hub',\n",
       " '\\x89ûïonly\\x89û\\x9d',\n",
       " 'biz',\n",
       " 'sinc',\n",
       " 'move',\n",
       " 'worst',\n",
       " 'strand',\n",
       " '104',\n",
       " 'show',\n",
       " 'tone',\n",
       " 'deaf',\n",
       " 'video',\n",
       " 'wifi',\n",
       " 'come',\n",
       " 'hah.not',\n",
       " 'ftw',\n",
       " 'cabin',\n",
       " \"'thank\",\n",
       " 'choic',\n",
       " 'comment',\n",
       " 'hard',\n",
       " 'solut',\n",
       " 'hotel',\n",
       " 'food',\n",
       " 'abc',\n",
       " 'live',\n",
       " 'nexttim',\n",
       " 'andthewinneri',\n",
       " 'understand',\n",
       " 'thx',\n",
       " 'thought',\n",
       " 'clarif',\n",
       " 'state',\n",
       " 'faundat',\n",
       " 'faith',\n",
       " 'judeo',\n",
       " 'cristian',\n",
       " 'ideologia',\n",
       " 'serious',\n",
       " 'asap',\n",
       " 'furiou',\n",
       " 'south',\n",
       " 'atl',\n",
       " 'ua1532',\n",
       " 'wilmington',\n",
       " 'charlott',\n",
       " 'drop',\n",
       " 'follow',\n",
       " 'someon',\n",
       " 'relax',\n",
       " 'etc',\n",
       " 'adv',\n",
       " 'notic',\n",
       " 'thankyou',\n",
       " 'dal-au',\n",
       " 'rout',\n",
       " 'support',\n",
       " 'orig',\n",
       " 'late',\n",
       " 'confirm',\n",
       " 'rate',\n",
       " 'around',\n",
       " 'afford',\n",
       " 'price',\n",
       " 'daytona',\n",
       " '500',\n",
       " 'proactiv',\n",
       " 'passeng',\n",
       " 'entertain',\n",
       " 'system',\n",
       " 'least',\n",
       " 'mag',\n",
       " 'center',\n",
       " 'bit',\n",
       " 'normal',\n",
       " 'receiv',\n",
       " 'central',\n",
       " 'baggageissu',\n",
       " 'smh',\n",
       " 'reason',\n",
       " 'lon',\n",
       " 'less',\n",
       " 'return',\n",
       " 'delaci',\n",
       " 'compassion',\n",
       " 'profession',\n",
       " 'despit',\n",
       " 'challeng',\n",
       " 'prioriti',\n",
       " '_ùîù_ùîù',\n",
       " 'seriou',\n",
       " 'worri',\n",
       " 'speak',\n",
       " 'ceo',\n",
       " 'battl',\n",
       " 'appeas',\n",
       " 'wall',\n",
       " 'street',\n",
       " 'waterburi',\n",
       " 'republican',\n",
       " 'enjoy',\n",
       " \"'re\",\n",
       " 'tough',\n",
       " 'comfort',\n",
       " 'advanc',\n",
       " 'ridicul',\n",
       " 'fresno',\n",
       " 'pittsburgh',\n",
       " '10pm',\n",
       " 'instead',\n",
       " '4pm',\n",
       " 'rerout',\n",
       " 'snowi',\n",
       " 'deal',\n",
       " 'troubl',\n",
       " 'rush',\n",
       " 'degre',\n",
       " 'bad',\n",
       " 'stillwait',\n",
       " 'luck',\n",
       " 'inform',\n",
       " 'els',\n",
       " 'head',\n",
       " 'laguardia',\n",
       " 'tray',\n",
       " 'tabl',\n",
       " 'size',\n",
       " 'mous',\n",
       " 'pad',\n",
       " 'pocket',\n",
       " 'singapor',\n",
       " 'three',\n",
       " 'without',\n",
       " 'known',\n",
       " 'tag',\n",
       " '580815',\n",
       " 'fleet',\n",
       " 'fleek',\n",
       " 'fav',\n",
       " 'disappear',\n",
       " 'miser',\n",
       " 'unhelp',\n",
       " 'letdown',\n",
       " 'what',\n",
       " '2034.',\n",
       " 'beyond',\n",
       " '834.',\n",
       " 'shouldnt',\n",
       " 'thre',\n",
       " 'switch',\n",
       " '2/2',\n",
       " 'cert',\n",
       " 'assum',\n",
       " 'clear',\n",
       " 'crisi',\n",
       " 'avert',\n",
       " 'beer',\n",
       " '1180',\n",
       " 'ewr',\n",
       " 'mco',\n",
       " 'rel',\n",
       " 'termin',\n",
       " 'miami',\n",
       " 'smelli',\n",
       " 'liter',\n",
       " 'stop',\n",
       " 'line',\n",
       " 'incred',\n",
       " 'gross',\n",
       " 'disappointment-yet',\n",
       " 'again-fli',\n",
       " 'four',\n",
       " 'properli',\n",
       " 'train',\n",
       " 'request',\n",
       " 'dead',\n",
       " 'littl',\n",
       " 'wonk',\n",
       " 'browser',\n",
       " 'css',\n",
       " 'shitshow',\n",
       " 'behind',\n",
       " 'counter',\n",
       " 'send',\n",
       " 'wrong',\n",
       " 'destination=rud',\n",
       " 'nyc',\n",
       " 'philli',\n",
       " 'leg',\n",
       " 'offens',\n",
       " 'mention',\n",
       " 'busi',\n",
       " 'owner',\n",
       " 'mortifi',\n",
       " 'act',\n",
       " 'blue',\n",
       " 'eye',\n",
       " 'firstlov',\n",
       " 'sad',\n",
       " 'distanc',\n",
       " 'iah-hnl',\n",
       " 'sfo',\n",
       " 'reactiv',\n",
       " 'sat',\n",
       " '3:30am',\n",
       " 'kid',\n",
       " 'starv',\n",
       " 'exhaust',\n",
       " 'partner',\n",
       " 'extrem',\n",
       " 'horribl',\n",
       " '160',\n",
       " '1946',\n",
       " 'heavi',\n",
       " 'gun',\n",
       " 'iwoulddoanythingforlov',\n",
       " 'brandmanc',\n",
       " 'lovesongfriday',\n",
       " 'monday',\n",
       " 'carolina',\n",
       " 'wednesday',\n",
       " 'accept',\n",
       " 'mi-boston',\n",
       " 'icelandair',\n",
       " 'iceland',\n",
       " 'vipliveinthevieyard',\n",
       " 'club',\n",
       " 'fee',\n",
       " 'life.stop',\n",
       " 'elizabeth',\n",
       " 'washington',\n",
       " 'dull',\n",
       " 'hook',\n",
       " 'connect',\n",
       " 'super',\n",
       " 'instal',\n",
       " '_ùõª_ùõª',\n",
       " 'term',\n",
       " '55min',\n",
       " 'layov',\n",
       " 'us755-aa2595',\n",
       " 'realist',\n",
       " '2595',\n",
       " 'held',\n",
       " 'middl',\n",
       " 'upgrad',\n",
       " 'emerg',\n",
       " 'nothappi',\n",
       " 'ua1002',\n",
       " 'chanc',\n",
       " 'ord',\n",
       " '117.',\n",
       " 'proud',\n",
       " 'w/custom',\n",
       " 'b/f',\n",
       " 'drope',\n",
       " 'left',\n",
       " 'son',\n",
       " 'duke',\n",
       " 'hat',\n",
       " '1761',\n",
       " 'mason',\n",
       " 'locat',\n",
       " 'impress',\n",
       " 'subpar',\n",
       " 'view',\n",
       " 'downtown',\n",
       " 'angel',\n",
       " 'hollywood',\n",
       " 'sign',\n",
       " 'rain',\n",
       " 'mountain',\n",
       " 'repres',\n",
       " 'disconnect',\n",
       " 'bother',\n",
       " 'decept',\n",
       " 'market',\n",
       " 'practic',\n",
       " 'retain',\n",
       " 'grant',\n",
       " 'neverflyunit',\n",
       " 'talk',\n",
       " 'stewardess',\n",
       " 'serv',\n",
       " 'drunk',\n",
       " 'drink',\n",
       " 'corpor',\n",
       " '480',\n",
       " 'particular',\n",
       " 'document',\n",
       " 'mileag',\n",
       " 'plu',\n",
       " 'idea',\n",
       " 'tsa',\n",
       " 'pre-check',\n",
       " 'profil',\n",
       " 'glitch',\n",
       " 'injur',\n",
       " 'dr.',\n",
       " 'swa',\n",
       " 'advisori',\n",
       " 'den',\n",
       " 'usxlon',\n",
       " '5/21',\n",
       " '5/22',\n",
       " 'correct',\n",
       " 'complaint',\n",
       " 'whoa',\n",
       " 'brave',\n",
       " 'world',\n",
       " 'air',\n",
       " 'repeat',\n",
       " 'polici',\n",
       " 'fuck',\n",
       " 'reevalu',\n",
       " 'endlessli',\n",
       " 'phl',\n",
       " 'ground',\n",
       " 'taxi',\n",
       " '11:30pm',\n",
       " 'aircraft',\n",
       " 'truth',\n",
       " 'resolv',\n",
       " 'offici',\n",
       " 'add',\n",
       " 'awesom',\n",
       " 'librari',\n",
       " 'doesn\\x89ûªt',\n",
       " 'english',\n",
       " 'yell',\n",
       " 'slowli',\n",
       " '-lga-ord',\n",
       " '711.',\n",
       " 'name',\n",
       " 'argument',\n",
       " 'iah',\n",
       " 'close',\n",
       " 'kudo',\n",
       " '1050',\n",
       " 'grr',\n",
       " 'special',\n",
       " 'memori',\n",
       " 'sweet',\n",
       " 'young',\n",
       " 'momma',\n",
       " 'kill',\n",
       " 'flightli',\n",
       " 'abroad',\n",
       " 'visit',\n",
       " 'b/c',\n",
       " 'traffic',\n",
       " 'dividend',\n",
       " 'member',\n",
       " 'text',\n",
       " '_ùõ©_ùõ©_ùõ©_ùõ©',\n",
       " '_ù÷á_ù÷á',\n",
       " 'import',\n",
       " 'patiencerunningout',\n",
       " 'nice',\n",
       " 'vibe',\n",
       " 'moodlight',\n",
       " 'takeoff',\n",
       " 'touchdown',\n",
       " 'moodlitmonday',\n",
       " 'sciencebehindtheexperi',\n",
       " 'share',\n",
       " 'fyi',\n",
       " 'twice',\n",
       " 'thing',\n",
       " 'pick',\n",
       " '1449',\n",
       " 'pbi',\n",
       " 'stow',\n",
       " 'aggrav',\n",
       " 'usual',\n",
       " 'wiyh',\n",
       " 'hello',\n",
       " 'sunni',\n",
       " 'west',\n",
       " 'palm',\n",
       " 'beach',\n",
       " 'jetbluerock',\n",
       " 'standbi',\n",
       " 'almost',\n",
       " '4hr',\n",
       " 'confåêfvf9yw',\n",
       " 'swrråê298033455',\n",
       " 'question',\n",
       " 'wife',\n",
       " 'bonu',\n",
       " 'vuelo24.',\n",
       " 'vuelos24.',\n",
       " 'sell',\n",
       " 'cheap',\n",
       " 'mad-nyc',\n",
       " 'usairway',\n",
       " 'trust',\n",
       " 'web',\n",
       " 'scam',\n",
       " 'boston',\n",
       " 'self',\n",
       " 'swipe',\n",
       " 'pass',\n",
       " 'difficult',\n",
       " 'easi',\n",
       " 'improvetheprocess',\n",
       " 'shanghai',\n",
       " 'handler',\n",
       " 'dfw',\n",
       " 'onboard',\n",
       " 'pre',\n",
       " 'schooler',\n",
       " 'develop',\n",
       " 'crash',\n",
       " 'everi',\n",
       " 'singl',\n",
       " 'advantag',\n",
       " 'mayweatherpacquiao',\n",
       " 'x__x',\n",
       " 'set',\n",
       " 'fitz',\n",
       " '1326',\n",
       " 'bwi/bo',\n",
       " 'fantast',\n",
       " 'canadaair',\n",
       " 'region',\n",
       " 'plain',\n",
       " 'invit',\n",
       " 'lock',\n",
       " 'creat',\n",
       " 'provid',\n",
       " 'complimentari',\n",
       " 'accommod',\n",
       " ...]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepering input for chi 2\n",
    "matrix_input = np.full((len(train_data),len(unique_words)), 0)\n",
    "\n",
    "for i in range (0,len(train_data)):\n",
    "    counter = 0\n",
    "    for word in unique_words:\n",
    "        if word in train_data[\"text\"][i]:\n",
    "            matrix_input[i][counter] = 1\n",
    "        counter = counter +1    \n",
    "\n",
    "lable_vector = train_data[\"airline_sentiment\"]\n",
    "\n",
    "matrix_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_input_pd = pd.DataFrame(data = matrix_input, columns = unique_words)\n",
    "#matrix_input_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       positive\n",
       "1       negative\n",
       "2       negative\n",
       "3       negative\n",
       "4       negative\n",
       "          ...   \n",
       "8779    negative\n",
       "8780    negative\n",
       "8781    negative\n",
       "8782    negative\n",
       "8783    negative\n",
       "Name: airline_sentiment, Length: 8784, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lable_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['appreci', 'flight', 'day', 'lost', 'guy', 'suck', 'peopl', 'n't',\n",
       "       'cancel', 'rebook', 'wait', 'minut', 'hold', 'fail', 'need', 'miss',\n",
       "       'bag', 'say', 'servic', 'daili', 'avgeek', 'due', 'time', 'get', 'min',\n",
       "       ''ve', 'thank', 'respons', 'hour', 'one', 'still', 'ûïat_us', 'experi',\n",
       "       'best', 'ever', 'disappoint', 'never', 'tri', 'said', 'flightl',\n",
       "       'excit', 'told', 'rude', 'issu', 'delay', 'plane', 'good', 'much',\n",
       "       'phone', 'gate', 'agent', 'excel', 'crew', 'unaccept', 'call', 'custom',\n",
       "       'job', 'answer', 'luggag', 'sit', 'love', 'great', 'baggag', 'worst',\n",
       "       'hotel', 'thx', 'follow', 'late', 'system', 'worri', 'ceo', 'battl',\n",
       "       'wall', 'street', 'ridicul', 'bad', 'fleet', 'fleek', 'line', 'view',\n",
       "       'awesom', 'kudo', 'fantast', 'journal', 'stuck', 'deserv', 'quick',\n",
       "       'outstand', 'southwest', 'vega', 'destinationdragon', 'flightr',\n",
       "       'beauti', 'passbook', 'rock', 'amaz', 'companion', 'winner', 'smooth',\n",
       "       'favorit'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "#primary_feature = sklearn.feature_selection.chi2(matrix_input, lable_vector)\n",
    "\n",
    "#primary_feature\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest \n",
    "from sklearn.feature_selection import chi2 \n",
    "  \n",
    "#Two features with highest chi-squared statistics are selected \n",
    "chi2_features = SelectKBest(chi2, k = 100) \n",
    "#X_kbest_features = chi2_features.fit_transform(matrix_input_pd, lable_vector) \n",
    "X_kbest_features = chi2_features.fit_transform(matrix_input_pd, lable_vector)\n",
    "\n",
    "X_kbest_features.shape\n",
    "# Reduced features \n",
    "Reduced_features = matrix_input_pd.columns[chi2_features.get_support()]\n",
    "\n",
    "Reduced_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>_golden</th>\n",
       "      <th>_unit_state</th>\n",
       "      <th>_trusted_judgments</th>\n",
       "      <th>_last_judgment_at</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment:confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason:confidence</th>\n",
       "      <th>...</th>\n",
       "      <th>destinationdragon</th>\n",
       "      <th>flightr</th>\n",
       "      <th>beauti</th>\n",
       "      <th>passbook</th>\n",
       "      <th>rock</th>\n",
       "      <th>amaz</th>\n",
       "      <th>companion</th>\n",
       "      <th>winner</th>\n",
       "      <th>smooth</th>\n",
       "      <th>favorit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11429</td>\n",
       "      <td>681462729</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 3:07</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9717</td>\n",
       "      <td>681461003</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 3:20</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>0.3464</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10153</td>\n",
       "      <td>681461443</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 6:20</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>975</td>\n",
       "      <td>681449647</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 2:14</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1511</td>\n",
       "      <td>681450373</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 6:57</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>0.6848</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   _unit_id  _golden _unit_state  _trusted_judgments  \\\n",
       "0       11429  681462729    False   finalized                   3   \n",
       "1        9717  681461003    False   finalized                   3   \n",
       "2       10153  681461443    False   finalized                   3   \n",
       "3         975  681449647    False   finalized                   3   \n",
       "4        1511  681450373    False   finalized                   3   \n",
       "\n",
       "  _last_judgment_at airline_sentiment  airline_sentiment:confidence  \\\n",
       "0      2/25/15 3:07          positive                           1.0   \n",
       "1      2/25/15 3:20          negative                           1.0   \n",
       "2      2/25/15 6:20          negative                           1.0   \n",
       "3      2/25/15 2:14          negative                           1.0   \n",
       "4      2/25/15 6:57          negative                           1.0   \n",
       "\n",
       "  negativereason  negativereason:confidence  ... destinationdragon flightr  \\\n",
       "0            NaN                        NaN  ...                 0       0   \n",
       "1     Can't Tell                     0.3464  ...                 0       0   \n",
       "2     Can't Tell                     1.0000  ...                 0       0   \n",
       "3     Can't Tell                     1.0000  ...                 0       0   \n",
       "4     Can't Tell                     0.6848  ...                 0       0   \n",
       "\n",
       "  beauti passbook  rock amaz companion winner  smooth favorit  \n",
       "0      0        0     0    0         0      0       0       0  \n",
       "1      0        0     0    0         0      0       0       0  \n",
       "2      0        0     0    0         0      0       0       0  \n",
       "3      0        0     0    0         0      0       0       0  \n",
       "4      0        0     0    0         0      0       0       0  \n",
       "\n",
       "[5 rows x 121 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final featuers\n",
    "\n",
    "#deleted_features = []\n",
    "#for feature in train_data.columns:\n",
    "#    if feature not in test_data.columns:\n",
    "#        deleted_features.append(feature)\n",
    "#        train_data.drop(columns=[feature])\n",
    "\n",
    "\n",
    "\n",
    "for feature in Reduced_features:\n",
    "    train_data.insert((len(train_data.columns)),feature, matrix_input_pd[feature] ,True) \n",
    "    \n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#building inputs for training model\n",
    "x_train = np.full((len(train_data),len(inf)), 0 ,  dtype=object)\n",
    "X_train_pd = pd.DataFrame(data = x_train, columns = inf)\n",
    "\n",
    "X_train_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = 0\n",
    "for feature in inf:\n",
    "    X_train_pd[feature] = train_data[feature]\n",
    "    counter = counter+1\n",
    "\n",
    "    \n",
    "X_train_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appreci</th>\n",
       "      <th>flight</th>\n",
       "      <th>day</th>\n",
       "      <th>lost</th>\n",
       "      <th>guy</th>\n",
       "      <th>suck</th>\n",
       "      <th>peopl</th>\n",
       "      <th>n't</th>\n",
       "      <th>cancel</th>\n",
       "      <th>rebook</th>\n",
       "      <th>...</th>\n",
       "      <th>destinationdragon</th>\n",
       "      <th>flightr</th>\n",
       "      <th>beauti</th>\n",
       "      <th>passbook</th>\n",
       "      <th>rock</th>\n",
       "      <th>amaz</th>\n",
       "      <th>companion</th>\n",
       "      <th>winner</th>\n",
       "      <th>smooth</th>\n",
       "      <th>favorit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   appreci  flight  day  lost  guy  suck  peopl  n't  cancel  rebook  ...  \\\n",
       "0        1       0    0     0    0     0      0    0       0       0  ...   \n",
       "1        0       1    1     1    0     0      0    0       0       0  ...   \n",
       "2        0       0    0     0    1     1      0    0       0       0  ...   \n",
       "3        0       0    0     0    0     0      0    0       0       0  ...   \n",
       "4        0       0    0     0    0     0      1    1       0       0  ...   \n",
       "\n",
       "   destinationdragon  flightr  beauti  passbook  rock  amaz  companion  \\\n",
       "0                  0        0       0         0     0     0          0   \n",
       "1                  0        0       0         0     0     0          0   \n",
       "2                  0        0       0         0     0     0          0   \n",
       "3                  0        0       0         0     0     0          0   \n",
       "4                  0        0       0         0     0     0          0   \n",
       "\n",
       "   winner  smooth  favorit  \n",
       "0       0       0        0  \n",
       "1       0       0        0  \n",
       "2       0       0        0  \n",
       "3       0       0        0  \n",
       "4       0       0        0  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for feature in Reduced_features:\n",
    "    X_train_pd.insert((len(X_train_pd.columns)),feature, matrix_input_pd[feature] ,True) \n",
    "    \n",
    "y_train = train_data[\"airline_sentiment\"]\n",
    "\n",
    "#Import Gaussian Naive Bayes model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "model = GaussianNB()\n",
    "\n",
    " \n",
    "#fill nan values\n",
    "\n",
    "X_train_pd.fillna(0)\n",
    "\n",
    "X_train_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model using the training sets\n",
    "X_train_pd.to_numpy()\n",
    "model.fit(X_train_pd.astype(np.float),y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building inputs for test model\n",
    "x_test = np.full((len(test_data),len(inf)), 0)\n",
    "X_test_pd = pd.DataFrame(data = x_test, columns = inf)\n",
    "\n",
    "#counter = 0\n",
    "#for feature in inf:\n",
    "#    X_test_pd[counter] = test_data[feature]\n",
    "#    counter = counter+1\n",
    "\n",
    "#building inputs for training model\n",
    "x_test = np.full((len(test_data),len(inf)), 0)\n",
    "X_test_pd = pd.DataFrame(data = x_test, columns = inf)\n",
    "\n",
    "for feature in Reduced_features:\n",
    "    X_test_pd.insert((len(X_test_pd.columns)),feature, matrix_input_pd[feature] ,True) \n",
    "\n",
    "y_true = test_data[\"airline_sentiment\"]\n",
    "\n",
    "y_pred = model.predict(X_test_pd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3777322404371585\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_true, y_pred))\n",
    "\n",
    "precision = precision_score(y_true, y_pred,average='weighted')\n",
    "\n",
    "#average_precision = average_precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred,average='macro')\n",
    "f1_macro = f1_score(y_true, y_pred, average='macro')\n",
    "f1_micro = f1_score(y_true, y_pred, average='micro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4545745245058099"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3292968520602679"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3064248811602481"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3777322404371585"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_micro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 50, 205,   0],\n",
       "       [164, 761,   0],\n",
       "       [  0,   0,   0]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_true, y_pred, labels=[\"positive\", \"negative\", \"netural\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
